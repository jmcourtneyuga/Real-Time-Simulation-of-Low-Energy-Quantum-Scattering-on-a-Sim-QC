{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213d256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63fb05c-84dd-41b0-9200-0965c4df201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created/verified directory: /home/jmc03846/lib\n",
      "Created/verified directory: /scratch/jmc03846/coefficient_cache\n",
      "Created/verified directory: /scratch/jmc03846/simulation_output\n",
      "Created/verified directory: /scratch/jmc03846/simulation_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import getpass\n",
    "import subprocess\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "# Get username\n",
    "USERNAME = getpass.getuser()\n",
    "HOME_PATH = f\"/home/{USERNAME}\"\n",
    "SCRATCH_PATH = f\"/scratch/{USERNAME}\"\n",
    "\n",
    "# Define paths\n",
    "LIB_DIR = os.path.join(HOME_PATH, \"lib\")\n",
    "CACHE_DIR = os.path.join(SCRATCH_PATH, \"coefficient_cache\")\n",
    "OUTPUT_DIR = os.path.join(SCRATCH_PATH, \"simulation_output\")\n",
    "DATA_DIR = os.path.join(SCRATCH_PATH, \"simulation_data\")\n",
    "\n",
    "# Create directories\n",
    "for directory in [LIB_DIR, CACHE_DIR, OUTPUT_DIR, DATA_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"Created/verified directory: {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ae71535-add5-4898-987d-ded126f937f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling C library...\n",
      "Command: gcc -O3 -fopenmp -fPIC -shared -o /home/jmc03846/lib/mobius_coefficients.so /home/jmc03846/mobius_coefficients_hp.c -lm\n",
      "✓ Successfully compiled to /home/jmc03846/lib/mobius_coefficients.so\n",
      "✓ Library size: 18,904 bytes\n",
      "\n",
      "Library ready for use!\n"
     ]
    }
   ],
   "source": [
    "# Compile C Library\n",
    "def compile_c_library():\n",
    "\n",
    "    #Look for the source file\n",
    "    c_source_path = os.path.join(HOME_PATH, \"precomp_coefficients.c\")\n",
    "    lib_path = os.path.join(LIB_DIR, \"precomp_coefficients.so\")\n",
    "    \n",
    "    # Check if source file exists\n",
    "    if not os.path.exists(c_source_path):\n",
    "        print(f\"Error: C code not found at {c_source_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Build compile command\n",
    "    compile_cmd = [\n",
    "        \"gcc\", \"-O3\", \"-fopenmp\", \"-fPIC\", \"-shared\",\n",
    "        \"-o\", lib_path,\n",
    "        c_source_path,\n",
    "        \"-lm\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"Compiling C library...\")\n",
    "    print(f\"Command: {' '.join(compile_cmd)}\")\n",
    "\n",
    "    #I made a safe compilation but it's not robust i.e. if the compilation fails everything stops, and it doesn't safely fix the error or\n",
    "    #make a strong second attempt to compile\n",
    "    try:\n",
    "        result = subprocess.run(compile_cmd, capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"C code Successfully compiled to {lib_path}\")\n",
    "            # Check file size to ensure it compiled properly\n",
    "            file_size = os.path.getsize(lib_path)\n",
    "            print(f\"Library size: {file_size:,} bytes\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Compilation failed:\")\n",
    "            print(result.stderr)\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error during compilation: {e}\")\n",
    "        return False\n",
    "\n",
    "# Compile the library\n",
    "if compile_c_library():\n",
    "    print(\"\\nLibrary ready\")\n",
    "else:\n",
    "    print(\"\\nLibrary not read, compilation failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c77734",
   "metadata": {},
   "source": [
    "# Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ecc299-afe2-4c29-9e2c-eba6408aaf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Magic numbers: \n",
    "#QUBITS_NUM\n",
    "#ANCILLA_QUBITS\n",
    "#START_TIME\n",
    "#TIMESTEP\n",
    "#STOP_TIME\n",
    "#VERTICAL_OFFSET\n",
    "#MASS M\n",
    "#BOX SIZE l\n",
    "#HBAR\n",
    "#X_0 INITIAL POSITION\n",
    "#P_0 INITIAL MOMENTUM\n",
    "#INITIAL WAVEPACKET WIDTH \\delta\n",
    "#POLYNOMIAL_TYPE\n",
    "#POLYNOMIAL PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9431f6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, transpile, assemble\n",
    "from qiskit.circuit.library.standard_gates import HGate, SGate, SdgGate, RYGate, CXGate, MCPhaseGate\n",
    "from qiskit.circuit.library import XGate, RXGate, CCXGate, CRXGate, RZGate, CRZGate, SwapGate, QFT\n",
    "from qiskit.quantum_info import Operator, SparsePauliOp, Statevector, partial_trace, DensityMatrix\n",
    "from qiskit_aer import Aer\n",
    "\n",
    "from scipy.optimize import differential_evolution, minimize, OptimizeResult, brentq\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numdifftools as nd\n",
    "import numpy as np\n",
    "from decimal import Decimal, getcontext\n",
    "\n",
    "import itertools\n",
    "from itertools import product, combinations\n",
    "from functools import partial, lru_cache\n",
    "from collections import defaultdict\n",
    "from queue import Queue\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import threading\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import tempfile\n",
    "import os\n",
    "import json\n",
    "import ctypes\n",
    "import struct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3ac02d-114f-40be-8c14-544e40d644b1",
   "metadata": {},
   "source": [
    "### Custom Imports|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e6e2d6-df6f-4f53-aadb-74094e96622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CustomOperations import * #imports cqft, ciqft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3551448c-a497-410c-8977-2a0f16958593",
   "metadata": {},
   "source": [
    "# How many qubits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb907c20-034a-4322-a7b5-818ac85a2616",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUBITS_NUM = 11 #number of Position Register qubits (longer runtime scales exponentially with number of qubits)\n",
    "start_time = 0.0 #start time\n",
    "timestep = 30.0 #Trotter step size (smaller step size, longer runtime, scales linearly)\n",
    "stop_time = 3000010.0 #stop time (longer stop_time, longer runtime total, scales linearly)\n",
    "trial = 1.0\n",
    "vertical_offset = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e287170",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = int(time.time())\n",
    "simulator_backend = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966036cc-da01-4f06-a05f-9f93cc2c9841",
   "metadata": {},
   "source": [
    "# **Magic** Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5b27371-51fa-45ac-921f-2739c05b9447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By Magic Parameters, I mean this in the way Computer scientists use the word \"magic\"\n",
    "#These are numbers that dictate how the whole system behaves\n",
    "\n",
    "#If using VQE for state preparation, you won't need x_0, p_0 or δ. The variational ansatz you import will produce a good approximation\n",
    "#of the wavepacket shape. You may need to adjust scaling or where the potential is centered based on the potential's ground state\n",
    "#The code is not robust to errors, so if you input an invalid term in the magic parameters, it'll throw up a red ERROR message instead\n",
    "#of actually handling the error.\n",
    "#If you're familiar with error messages though, it should be pretty clear what's going wrong.\n",
    "\n",
    "\n",
    "#This isn't a mysterious code. Some parts are rather convoluted, but the algorithm is super simple, being a Suzuki-Trotter evolution of a Hamiltonian\n",
    "#H = T+V. The partial tracing of the density matrix is simple, the readouts should be legible. The only part which I recommend you leave alone is the \n",
    "#specific parameterization for the potential energy terms. I made those myself, those numbers are correct and directly correspond to the polynomial degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce1eee27-af78-48ef-b1b6-2dcd110bdbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_1 = 72835 #argon\n",
    "m_2 = 72835 #argon\n",
    "L = 60 #box size\n",
    "ħ = 1.0 #atomic units for hbar\n",
    "\n",
    "d = L/2 #Box is defined from (-d to d)\n",
    "N = 2**QUBITS_NUM #number of states\n",
    "Δ_x = L / N #position grid spacing\n",
    "Δ_p  = 2*np.pi / (N * Δ_x) #momentum grid spacing\n",
    "\n",
    "x_0 = 20 - Δ_x/2 #need Δ_x shift to initialize in the true middle, due to an even number of states.\n",
    "p_0 = -0.8 #momentum of initialized Gaussian wavepacket\n",
    "δ = 0.55 #width of initialized Gaussian wavepacket\n",
    "\n",
    "epsilon = 0.000379067\n",
    "sigma = 6.430738\n",
    "\n",
    "Nyquist = np.pi / Δ_x #max / min momentum\n",
    "\n",
    "PolynomialType = \"Lennard-Jones\"\n",
    "current_params = [epsilon, sigma]\n",
    "\n",
    "#reduced mass\n",
    "m = (m_1 * m_2) / (m_1 + m_2)\n",
    "\n",
    "statevector = []\n",
    "System = f\"Ar-Ar_fscattering_{L}L_{timestep}timestep\"\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba84e5-7458-426b-b96a-e8f41baf80de",
   "metadata": {},
   "source": [
    "# DEFINE KINETIC COEFFICIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24b7f5be-cea3-46e0-bf6e-56115cea25b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "β_kinetic = (-Nyquist - p_0) / (Δ_p)\n",
    "γ_kinetic = (Δ_p)**2 / (2*m*ħ)\n",
    "\n",
    "θ_0 = -timestep * (γ_kinetic * β_kinetic**2)  # Global Phase\n",
    "θ_1 = -2 * timestep * γ_kinetic * β_kinetic  # Linear Term\n",
    "θ_2 = -timestep * γ_kinetic  # Quadratic term\n",
    "kinetic_coeffs = [θ_0, θ_1, θ_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d104dd0f-c52f-4651-b020-39b284f6d3dd",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33cc55ce-0858-4454-8dc6-1fddb6df84c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_highbit_state_z_basis_single_tau(main_circuit, position_register, QUBITS_NUM, tau, filename=\"ancilla_states.txt\"):\n",
    "    simulator = Aer.get_backend('statevector_simulator')\n",
    "    transpiled_circuit = transpile(main_circuit, simulator)\n",
    "    result = simulator.run(transpiled_circuit).result()\n",
    "    statevector = Statevector(result.get_statevector())\n",
    "    pauli_z = np.array([[1, 0], [0, -1]])\n",
    "    ancilla_index = main_circuit.find_bit(position_register[QUBITS_NUM-1]).index\n",
    "    z_expectation_value = np.real(statevector.expectation_value(Operator(pauli_z), [ancilla_index]))\n",
    "    population_fraction = (z_expectation_value + 1) / 2\n",
    "    with open(filename, \"a\") as file:\n",
    "        file.write(f\"{tau}\\t{population_fraction}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ddecea-959d-4c1e-9649-78db1737b730",
   "metadata": {},
   "source": [
    "# Record Momentum Distribution after CQFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f224aae3-4a81-4e0d-83e4-145a2d2ebee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchedDataRecorder:\n",
    "    def __init__(self, batch_size=100):\n",
    "        self.batch_size = batch_size\n",
    "        self.position_buffer = []\n",
    "        self.momentum_buffer = []\n",
    "        self.ancilla_buffer = []\n",
    "        self.lock = threading.Lock()\n",
    "        self.write_threads = []\n",
    "        \n",
    "    def add_position_record(self, time, probabilities, filename):\n",
    "        with self.lock:\n",
    "            # Store exact copy to avoid any modification issues\n",
    "            self.position_buffer.append((time, np.copy(probabilities), filename))\n",
    "            \n",
    "            if len(self.position_buffer) >= self.batch_size:\n",
    "                self._flush_position_buffer_async()\n",
    "                \n",
    "    def add_momentum_record(self, time, probabilities, filename):\n",
    "        with self.lock:\n",
    "            # Store exact copy\n",
    "            self.momentum_buffer.append((time, np.copy(probabilities), filename))\n",
    "            \n",
    "            if len(self.momentum_buffer) >= self.batch_size:\n",
    "                self._flush_momentum_buffer_async()\n",
    "                \n",
    "    def add_ancilla_record(self, time, population_fraction, filename):\n",
    "        with self.lock:\n",
    "            self.ancilla_buffer.append((time, population_fraction, filename))\n",
    "            \n",
    "            if len(self.ancilla_buffer) >= self.batch_size:\n",
    "                self._flush_ancilla_buffer_async()\n",
    "                \n",
    "    def _flush_position_buffer_async(self):\n",
    "        if not self.position_buffer:\n",
    "            return\n",
    "            \n",
    "        # Group by filename\n",
    "        files_data = {}\n",
    "        for time, probs, filename in self.position_buffer:\n",
    "            if filename not in files_data:\n",
    "                files_data[filename] = []\n",
    "            files_data[filename].append((time, probs))\n",
    "        \n",
    "        self.position_buffer.clear()\n",
    "        \n",
    "        # Start async write for each file\n",
    "        for filename, data in files_data.items():\n",
    "            thread = threading.Thread(\n",
    "                target=self._write_position_data,\n",
    "                args=(filename, data)\n",
    "            )\n",
    "            thread.start()\n",
    "            self.write_threads.append(thread)\n",
    "            \n",
    "    def _flush_momentum_buffer_async(self):\n",
    "        if not self.momentum_buffer:\n",
    "            return\n",
    "            \n",
    "        # Group by filename\n",
    "        files_data = {}\n",
    "        for time, probs, filename in self.momentum_buffer:\n",
    "            if filename not in files_data:\n",
    "                files_data[filename] = []\n",
    "            files_data[filename].append((time, probs))\n",
    "        \n",
    "        self.momentum_buffer.clear()\n",
    "        \n",
    "        # Start async write for each file\n",
    "        for filename, data in files_data.items():\n",
    "            thread = threading.Thread(\n",
    "                target=self._write_momentum_data,\n",
    "                args=(filename, data)\n",
    "            )\n",
    "            thread.start()\n",
    "            self.write_threads.append(thread)\n",
    "            \n",
    "    def _flush_ancilla_buffer_async(self):\n",
    "        if not self.ancilla_buffer:\n",
    "            return\n",
    "            \n",
    "        # Group by filename\n",
    "        files_data = {}\n",
    "        for time, pop, filename in self.ancilla_buffer:\n",
    "            if filename not in files_data:\n",
    "                files_data[filename] = []\n",
    "            files_data[filename].append((time, pop))\n",
    "        \n",
    "        self.ancilla_buffer.clear()\n",
    "        \n",
    "        # Start async write for each file\n",
    "        for filename, data in files_data.items():\n",
    "            thread = threading.Thread(\n",
    "                target=self._write_ancilla_data,\n",
    "                args=(filename, data)\n",
    "            )\n",
    "            thread.start()\n",
    "            self.write_threads.append(thread)\n",
    "            \n",
    "    def _write_position_data(self, filename, data):\n",
    "        with open(filename, 'a') as f:\n",
    "            for time, probs in data:\n",
    "                line = f\"{time:.1f}\\t\" + \"\\t\".join(f\"{x:.14f}\" for x in probs) + \"\\n\"\n",
    "                f.write(line)\n",
    "                \n",
    "    def _write_momentum_data(self, filename, data):\n",
    "        with open(filename, 'a') as f:\n",
    "            for time, probs in data:\n",
    "                line = f\"{time:.1f}\\t\" + \"\\t\".join(f\"{x:.14f}\" for x in probs) + \"\\n\"\n",
    "                f.write(line)\n",
    "                \n",
    "    def _write_ancilla_data(self, filename, data):\n",
    "        with open(filename, 'a') as f:\n",
    "            for time, pop in data:\n",
    "                f.write(f\"{time}\\t{pop}\\n\")\n",
    "                \n",
    "    def flush_all(self):\n",
    "        with self.lock:\n",
    "            self._flush_position_buffer_async()\n",
    "            self._flush_momentum_buffer_async()\n",
    "            self._flush_ancilla_buffer_async()\n",
    "            \n",
    "        # Wait for all writes to complete\n",
    "        self.wait_for_writes()\n",
    "        \n",
    "    def wait_for_writes(self):\n",
    "        for thread in self.write_threads:\n",
    "            if thread.is_alive():\n",
    "                thread.join()\n",
    "        self.write_threads.clear()\n",
    "        \n",
    "    def cleanup_finished_threads(self):\n",
    "        self.write_threads = [t for t in self.write_threads if t.is_alive()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5aeefce-6fd3-499c-93d5-e12d821b2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_highbit_state_z_basis_single_tau(main_circuit, position_register, QUBITS_NUM, tau, recorder, filename):\n",
    "    simulator = Aer.get_backend('statevector_simulator')\n",
    "    transpiled_circuit = transpile(main_circuit, simulator)\n",
    "    result = simulator.run(transpiled_circuit).result()\n",
    "    statevector = Statevector(result.get_statevector())\n",
    "    pauli_z = np.array([[1, 0], [0, -1]])\n",
    "    ancilla_index = main_circuit.find_bit(position_register[QUBITS_NUM-1]).index\n",
    "    z_expectation_value = np.real(statevector.expectation_value(Operator(pauli_z), [ancilla_index]))\n",
    "    population_fraction = (z_expectation_value + 1) / 2\n",
    "    \n",
    "    recorder.add_ancilla_record(tau, population_fraction, filename)\n",
    "\n",
    "\n",
    "def record_momentum_distribution(circuit, position_register, tau, recorder, filename):\n",
    "    #Uses batched input/output\n",
    "    simulator = Aer.get_backend('statevector_simulator')\n",
    "    transpiled_circuit = transpile(circuit, simulator)\n",
    "    result = simulator.run(transpiled_circuit).result()\n",
    "    statevector = Statevector(result.get_statevector())\n",
    "    rho_position = DensityMatrix(statevector)\n",
    "    probabilities = np.real(np.diag(rho_position.data))\n",
    "    probabilities = np.flip(probabilities)\n",
    "    \n",
    "    recorder.add_momentum_record(tau, probabilities, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c6ff2-c475-4220-b096-2be4cbfe5e32",
   "metadata": {},
   "source": [
    "# Calculate Potentials for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36a9c506-544c-41b9-b0ac-e4c58ebb39c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumPotential:\n",
    "    def __init__(self, params, vertical_offset=0.0):\n",
    "        self.params = params\n",
    "        self.vertical_offset = vertical_offset\n",
    "        self.d = d\n",
    "        self.Δ_x = Δ_x\n",
    "        \n",
    "    def calculate_classical(self, x_values, scale_factor=1.0):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def apply_to_circuit(self, circuit, position_register, τ):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daac5c8f-0527-4737-8dff-cd47ad58562e",
   "metadata": {},
   "source": [
    "# Initialize Gaussian Wavepacket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6dffa63-458c-456b-971a-c7dc7825e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_gaussian_wavepacket(x_0, p_0, δ):\n",
    "    psi = np.zeros(N, dtype=complex)\n",
    "    norm_factor = (1/(2*np.pi*δ**2))**(1/4)\n",
    "    \n",
    "    for position in range(N):\n",
    "        x = -d + position * Δ_x\n",
    "        gaussian = np.exp(-(x - x_0)**2 / (4*δ**2))\n",
    "        psi[position] = gaussian\n",
    "    \n",
    "    psi = norm_factor * psi\n",
    "    final_norm = np.sqrt(np.sum(np.abs(psi)**2))\n",
    "    psi = psi / final_norm\n",
    "    \n",
    "    return psi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51c2835-1b3a-4c3f-ab1d-e4bbd30d3430",
   "metadata": {},
   "source": [
    "# Get Expectation Values Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "573b7e64-30c0-46ff-8e26-6ee5d1a661c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_expectation_value(probabilities, positions, box_size=4):\n",
    "    x_min = 0\n",
    "    x_max = L\n",
    "    box_size = x_max - x_min\n",
    "    scaling = box_size / len(positions)\n",
    "    real_positions = np.linspace(x_min, x_max, len(positions))\n",
    "    expectation = np.sum(probabilities * real_positions)\n",
    "    return expectation\n",
    "\n",
    "def calculate_p_expectation_value(probabilities, positions, box_size=4):\n",
    "    x_min = -d\n",
    "    x_max = d\n",
    "    box_size = x_max - x_min\n",
    "    scaling = box_size / len(positions)\n",
    "    real_positions = np.linspace(x_min, x_max, len(positions))\n",
    "    expectation = np.sum(probabilities * real_positions)\n",
    "    return expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27e83ef5-dec3-4a7d-a307-a3bc8273ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_phase(circuit, angle, register):\n",
    "    circuit.p(angle, register[0])\n",
    "    circuit.x(register[0])\n",
    "    circuit.p(angle, register[0])\n",
    "    circuit.x(register[0])\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0923ced-6902-4386-9da0-289d0072df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kinetic_first_order(circuit, angle, register, QUBITS_NUM):\n",
    "    for qubit in range(QUBITS_NUM):\n",
    "        position_scaling = 2**qubit\n",
    "        circuit.p(angle * position_scaling, register[qubit])\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "223e9599-019c-4aad-8e10-9d6b869ff90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kinetic_second_order(circuit, angle, register, QUBITS_NUM):\n",
    "    for control in range(QUBITS_NUM):\n",
    "        bit_order = 2 * control\n",
    "        position_scaling = 2**bit_order\n",
    "        circuit.p(angle * position_scaling, register[control])\n",
    "        \n",
    "        for target in range(QUBITS_NUM):\n",
    "            if target != control:\n",
    "                bit_order = control + target\n",
    "                position_scaling = 2**bit_order\n",
    "                circuit.cp(angle * position_scaling, register[control], register[target])\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b7f2e91-c303-49cd-8944-989d087aa21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kinetic_term(circuit, position_register, QUBITS_NUM, τ, kinetic_coeffs):\n",
    "    θ_0, θ_1, θ_2 = kinetic_coeffs \n",
    "    global_phase(circuit, θ_0, position_register)\n",
    "    kinetic_first_order(circuit, θ_1, position_register, QUBITS_NUM)\n",
    "    kinetic_second_order(circuit, θ_2, position_register, QUBITS_NUM)\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5efdc146-929b-4562-a4a3-7774cdb5e7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EffectivePotential(QuantumPotential):\n",
    "    def __init__(self, lj_params, centrifugal_params, vertical_offset=0.0, \n",
    "                 coefficients_by_power=None):\n",
    "        all_params = lj_params + centrifugal_params\n",
    "        super().__init__(all_params, vertical_offset)\n",
    "    \n",
    "        self.epsilon = lj_params[0]\n",
    "        self.sigma = lj_params[1]\n",
    "        self.partial_wave = centrifugal_params[0]\n",
    "        self.m = centrifugal_params[1]\n",
    "\n",
    "        self.coefficients_by_power = coefficients_by_power or {}\n",
    "    \n",
    "    def calculate_classical(self, x_values, scale_factor=1.0):\n",
    "        x_safe = np.where(x_values > 0, x_values, 1e-10)\n",
    "        \n",
    "        # LJ potential\n",
    "        sigma_over_r = self.sigma / x_safe\n",
    "        V_lj = 4 * self.epsilon * ((sigma_over_r)**12 - (sigma_over_r)**6)\n",
    "        \n",
    "        # Centrifugal potential (only if ℓ > 0)\n",
    "        if self.partial_wave > 0:\n",
    "            V_cent = (self.partial_wave * (self.partial_wave + 1)) / (2 * self.m * x_safe**2)\n",
    "        else:\n",
    "            V_cent = 0\n",
    "        \n",
    "        return (V_lj + V_cent) * scale_factor + self.vertical_offset\n",
    "    \n",
    "    def apply_to_circuit(self, circuit, position_register, τ):\n",
    "        n_qubits = len(position_register)\n",
    "        \n",
    "        for power, coefficients in self.coefficients_by_power.items():\n",
    "            discretization_factor = (1.0 / (L/N)) ** power \n",
    "            \n",
    "            for indices_tuple, physical_coefficient in coefficients.items():\n",
    "                angle = -τ * physical_coefficient * discretization_factor\n",
    "                \n",
    "                num_controls = len(indices_tuple)\n",
    "                \n",
    "                if num_controls == 1:\n",
    "                    circuit.p(angle, position_register[indices_tuple[0]])\n",
    "                else:\n",
    "                    controls = [position_register[i] for i in indices_tuple[:-1]]\n",
    "                    target = position_register[indices_tuple[-1]]\n",
    "                    circuit.append(MCPhaseGate(angle, num_controls-1), controls + [target])\n",
    "        \n",
    "        return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d4dc119-c5f0-470e-80ae-b3a383297b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_cached_coefficients(lj_cached_coeffs, centrifugal_cached_coeffs, lj_params, cent_params):\n",
    "    combined_by_power = {}\n",
    "    \n",
    "    # Extract physical parameters\n",
    "    epsilon = lj_params[0]  \n",
    "    sigma = lj_params[1]\n",
    "    l = cent_params[0]  # Angular momentum quantum number\n",
    "    mu = cent_params[1]  # Reduced mass\n",
    "    \n",
    "    # LJ repulsive term:\n",
    "    if lj_cached_coeffs and 12 in lj_cached_coeffs:\n",
    "        if epsilon != 0: \n",
    "            combined_by_power[12] = {}\n",
    "            physical_coeff_12 = 4 * epsilon * (sigma**12)\n",
    "            for indices_tuple, precomp_coeff in lj_cached_coeffs[12].items():\n",
    "                combined_by_power[12][indices_tuple] = physical_coeff_12 * precomp_coeff\n",
    "    \n",
    "    # LJ attractive term:\n",
    "    if lj_cached_coeffs and 6 in lj_cached_coeffs:\n",
    "        if epsilon != 0: \n",
    "            combined_by_power[6] = {}\n",
    "            physical_coeff_6 = -4 * epsilon * (sigma**6)\n",
    "            for indices_tuple, precomp_coeff in lj_cached_coeffs[6].items():\n",
    "                combined_by_power[6][indices_tuple] = physical_coeff_6 * precomp_coeff\n",
    "    \n",
    "    # Centrifugal term:\n",
    "    if centrifugal_cached_coeffs and 2 in centrifugal_cached_coeffs:\n",
    "        if l > 0: \n",
    "            combined_by_power[2] = {}\n",
    "            physical_coeff_2 = l * (l + 1) / (2 * mu)\n",
    "            for indices_tuple, precomp_coeff in centrifugal_cached_coeffs[2].items():\n",
    "                combined_by_power[2][indices_tuple] = physical_coeff_2 * precomp_coeff\n",
    "    \n",
    "    return combined_by_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b87251e-c756-4862-b3f8-25547972314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set decimal precision for Python side\n",
    "getcontext().prec = 50  # 50 decimal places\n",
    "\n",
    "class FastLJCoefficientsHP:\n",
    "    def __init__(self, lib_path=None):\n",
    "        if lib_path is None:\n",
    "            lib_path = os.path.join(LIB_DIR, \"precomp_coefficients.so\")\n",
    "        \n",
    "        if not os.path.exists(lib_path):\n",
    "            raise FileNotFoundError(f\"High-precision library not found at {lib_path}\")\n",
    "        \n",
    "        self.lib = ctypes.CDLL(lib_path)\n",
    "        \n",
    "        # Define function signatures using double interface\n",
    "        # The C code internally uses long double but exports as double\n",
    "        self.lib.compute_lj_coefficients.argtypes = [\n",
    "            ctypes.c_int,     # n_qubits\n",
    "            ctypes.c_double,  # epsilon (not used)\n",
    "            ctypes.c_double,  # sigma (not used)\n",
    "            ctypes.POINTER(ctypes.c_double),  # coeffs_12\n",
    "            ctypes.POINTER(ctypes.c_double),  # coeffs_6\n",
    "        ]\n",
    "        \n",
    "        self.lib.compute_arbitrary_power_coefficients.argtypes = [\n",
    "            ctypes.c_int,     # n_qubits\n",
    "            ctypes.c_int,     # power\n",
    "            ctypes.POINTER(ctypes.c_double),  # output\n",
    "        ]\n",
    "        \n",
    "        self.lib.print_precision_info.argtypes = []\n",
    "        self.lib.test_precision.argtypes = []\n",
    "        \n",
    "        # For string-based high precision export\n",
    "        self.lib.compute_lj_coefficients_string.argtypes = [\n",
    "            ctypes.c_int,                    # n_qubits\n",
    "            ctypes.POINTER(ctypes.c_char),   # coeffs_12_strings\n",
    "            ctypes.POINTER(ctypes.c_char),   # coeffs_6_strings\n",
    "            ctypes.c_int                     # string_length\n",
    "        ]\n",
    "        \n",
    "        # Print precision info on initialization\n",
    "        print(\"Initializing high-precision library...\")\n",
    "        self.lib.print_precision_info()\n",
    "    \n",
    "    def compute_lj_coefficients(self, n_qubits, epsilon, sigma, L, N):\n",
    "        n_states = 1 << n_qubits\n",
    "        string_length = 64 \n",
    "    \n",
    "        use_string_export = True\n",
    "        \n",
    "        if use_string_export and hasattr(self.lib, 'compute_lj_coefficients_string'):\n",
    "            coeffs_12_strings = (ctypes.c_char * (n_states * string_length))()\n",
    "            coeffs_6_strings = (ctypes.c_char * (n_states * string_length))()\n",
    "            \n",
    "            print(f\"Computing high-precision coefficients for {n_qubits} qubits (string export)...\")\n",
    "            self.lib.compute_lj_coefficients_string(\n",
    "                n_qubits, \n",
    "                coeffs_12_strings, \n",
    "                coeffs_6_strings, \n",
    "                string_length\n",
    "            )\n",
    "            \n",
    "            coeffs_12 = []\n",
    "            coeffs_6 = []\n",
    "            for i in range(n_states):\n",
    "                str_12 = coeffs_12_strings[i*string_length:(i+1)*string_length].decode('utf-8').strip('\\x00')\n",
    "                str_6 = coeffs_6_strings[i*string_length:(i+1)*string_length].decode('utf-8').strip('\\x00')\n",
    "                \n",
    "                try:\n",
    "                    coeffs_12.append(Decimal(str_12) if str_12 else Decimal('0'))\n",
    "                    coeffs_6.append(Decimal(str_6) if str_6 else Decimal('0'))\n",
    "                except:\n",
    "                    coeffs_12.append(Decimal('0'))\n",
    "                    coeffs_6.append(Decimal('0'))\n",
    "        else:\n",
    "            # Fallback: Use double interface (less precision)\n",
    "            coeffs_12_double = (ctypes.c_double * n_states)()\n",
    "            coeffs_6_double = (ctypes.c_double * n_states)()\n",
    "            \n",
    "            print(f\"Computing coefficients for {n_qubits} qubits (double precision fallback)...\")\n",
    "            self.lib.compute_lj_coefficients(\n",
    "                n_qubits, 0.0, 0.0, \n",
    "                coeffs_12_double, coeffs_6_double\n",
    "            )\n",
    "            \n",
    "            # Convert to Decimal\n",
    "            coeffs_12 = [Decimal(repr(coeffs_12_double[i])) for i in range(n_states)]\n",
    "            coeffs_6 = [Decimal(repr(coeffs_6_double[i])) for i in range(n_states)]\n",
    "        \n",
    "        # Apply physical scaling with high precision\n",
    "        epsilon = Decimal(repr(epsilon))\n",
    "        sigma = Decimal(repr(sigma))\n",
    "        L = Decimal(repr(L))\n",
    "        N = Decimal(repr(N))\n",
    "        \n",
    "        # Convert to Python dictionaries\n",
    "        result = {6: {}, 12: {}}\n",
    "        \n",
    "        for i in range(1, n_states):\n",
    "            indices = self._bitset_to_indices(i, n_qubits)\n",
    "            \n",
    "            try:\n",
    "                coeff_12 = coeffs_12[i]\n",
    "                coeff_6 = coeffs_6[i]\n",
    "                \n",
    "                if coeff_12 != 0:\n",
    "                    result[12][tuple(indices)] = float(coeff_12)\n",
    "                    \n",
    "                if coeff_6 != 0:\n",
    "                    result[6][tuple(indices)] = float(coeff_6)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error processing coefficient {i}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"Computed LJ coefficients:\")\n",
    "        print(f\"  12th power: {len(result[12])} non-zero coefficients\")\n",
    "        print(f\"  6th power: {len(result[6])} non-zero coefficients\")\n",
    "        \n",
    "        # Show sample coefficients\n",
    "        if result[12]:\n",
    "            # Check some critical single-bit states\n",
    "            for bit in [11, 12, 13]:\n",
    "                state_tuple = (bit,)\n",
    "                if state_tuple in result[12]:\n",
    "                    print(f\"  State 2^{bit} = {2**bit}: coeff_12 = {result[12][state_tuple]:.10e}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def compute_centrifugal_coefficients(self, n_qubits, l_value, m, L, N):\n",
    "        n_states = 1 << n_qubits\n",
    "        coeffs_2 = (ctypes.c_double * n_states)()\n",
    "        \n",
    "        # Get coefficients for power 2\n",
    "        self.lib.compute_arbitrary_power_coefficients(n_qubits, 2, coeffs_2)\n",
    "        \n",
    "        # High-precision scaling\n",
    "        l = Decimal(repr(l_value))\n",
    "        mu = Decimal(repr(m))\n",
    "        L = Decimal(repr(L))\n",
    "        N = Decimal(repr(N))\n",
    "        \n",
    "        physical_coeff = l * (l + Decimal('1')) / (Decimal('2') * mu)\n",
    "        \n",
    "        print(f\"Centrifugal scaling for l = {l_value}:\")\n",
    "        print(f\"  Physical coefficient: {physical_coeff:.25e}\")\n",
    "        \n",
    "        result = {}\n",
    "        \n",
    "        for i in range(1, n_states):\n",
    "            indices = self._bitset_to_indices(i, n_qubits)\n",
    "            try:\n",
    "                precomp_coeff = Decimal(repr(coeffs_2[i]))\n",
    "                if precomp_coeff != 0:\n",
    "                    result[tuple(indices)] = float(precomp_coeff)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing coefficient {i}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"  {len(result)} non-zero coefficients\")\n",
    "        return {2: result}\n",
    "    \n",
    "    def _bitset_to_indices(self, bitset, n_qubits):\n",
    "        indices = []\n",
    "        for i in range(n_qubits):\n",
    "            if bitset & (1 << i):\n",
    "                indices.append(i)\n",
    "        return sorted(indices)\n",
    "    \n",
    "    def verify_precision(self):\n",
    "        print(\"\\nRunning precision verification...\")\n",
    "        if hasattr(self.lib, 'test_precision'):\n",
    "            self.lib.test_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07b69d35-3e4c-4793-b746-3f7b045438ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling high-precision C library...\n",
      "Command: gcc -O3 -fopenmp -fPIC -shared -mlong-double-128 -std=c11 -Wall -Wextra -o /home/jmc03846/lib/mobius_coefficients_hp.so /home/jmc03846/mobius_coefficients_hp.c -lm\n",
      "✓ Successfully compiled to /home/jmc03846/lib/mobius_coefficients_hp.so\n",
      "✓ Library size: 112,888 bytes\n",
      "\n",
      "High-precision library ready!\n"
     ]
    }
   ],
   "source": [
    "def compile_library():\n",
    "    c_source_path = os.path.join(HOME_PATH, \"precomp_coefficients.c\")\n",
    "    lib_path = os.path.join(LIB_DIR, \"precomp_coefficients.so\")\n",
    "    \n",
    "    if not os.path.exists(c_source_path):\n",
    "        print(f\"ERROR: C source file not found at {c_source_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Compile with extended precision flags\n",
    "    compile_cmd = [\n",
    "        \"gcc\", \n",
    "        \"-O3\",                    # Optimization\n",
    "        \"-fopenmp\",               # OpenMP parallelization\n",
    "        \"-fPIC\",                  # Position independent code\n",
    "        \"-shared\",                # Shared library\n",
    "        \"-mlong-double-128\",      # Force 128-bit long double if available\n",
    "        \"-std=c11\",               # C11 standard\n",
    "        \"-Wall\",                  # All warnings\n",
    "        \"-Wextra\",              \n",
    "        \"-o\", lib_path,\n",
    "        c_source_path,\n",
    "        \"-lm\"                  \n",
    "    ]\n",
    "    \n",
    "    print(f\"Compiling high-precision C library...\")\n",
    "    print(f\"Command: {' '.join(compile_cmd)}\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(compile_cmd, capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"Successfully compiled to {lib_path}\")\n",
    "            file_size = os.path.getsize(lib_path)\n",
    "            print(f\"Library size: {file_size:,} bytes\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Compilation failed:\")\n",
    "            print(result.stderr)\n",
    "            print(\"\\nRetrying without 128-bit long double flag...\")\n",
    "            compile_cmd.remove(\"-mlong-double-128\")\n",
    "            result = subprocess.run(compile_cmd, capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                print(f\"Successfully compiled with default long double precision\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"Compilation failed again:\")\n",
    "                print(result.stderr)\n",
    "                return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error during compilation: {e}\")\n",
    "        return False\n",
    "\n",
    "if compilecoeff_library():\n",
    "    print(\"\\nHigh-precision library ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61e6d93e-2f29-40c5-ab71-1b6d720b25e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_cache_coefficients(potential_type, params, n_qubits,\n",
    "                                   max_power=12, n_cores=None,\n",
    "                                   cache_dir=None, use_high_precision=True):\n",
    "    if cache_dir is None:\n",
    "        cache_dir = CACHE_DIR\n",
    "    \n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    \n",
    "    precision_tag = \"hp\" if use_high_precision else \"dp\"\n",
    "    param_str = \"_\".join([f\"{p}\".replace('.', 'p') for p in params])\n",
    "    cache_key = f\"{potential_type}_{n_qubits}q_L{L}_N{N}_{precision_tag}_{param_str}\"\n",
    "    cache_file = os.path.join(cache_dir, f\"{cache_key}.pkl\")\n",
    "    lock_file = os.path.join(cache_dir, f\"{cache_key}.lock\")\n",
    "\n",
    "    got_lock = False\n",
    "    try:\n",
    "        while not os.path.exists(cache_file):\n",
    "            try:\n",
    "                os.close(os.open(lock_file, os.O_CREAT | os.O_EXCL))\n",
    "                got_lock = True\n",
    "                print(f\"Process {os.getpid()} acquired lock for {cache_key}\")\n",
    "                break \n",
    "            except FileExistsError:\n",
    "                time.sleep(random.uniform(0.5, 1.5))\n",
    "\n",
    "        if os.path.exists(cache_file):\n",
    "            try:\n",
    "                with open(cache_file, 'rb') as f:\n",
    "                    return pickle.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"Cache loading failed for {os.getpid()}: {e}, recomputing...\")\n",
    "\n",
    "        if got_lock:\n",
    "            print(f\"Process {os.getpid()} computing {potential_type} coefficients...\")\n",
    "            if use_high_precision:\n",
    "                fast_computer = FastLJCoefficientsHP()\n",
    "            else:\n",
    "                raise NotImplementedError(\"Standard precision not implemented, and the high precision code failed :(\")\n",
    "\n",
    "            if potential_type == \"Lennard-Jones\":\n",
    "                epsilon, sigma = params\n",
    "                coefficients = fast_computer.compute_lj_coefficients(n_qubits, epsilon, sigma, L, N)\n",
    "            elif potential_type == \"Centrifugal\":\n",
    "                l_value, m = params\n",
    "                coefficients = fast_computer.compute_centrifugal_coefficients(n_qubits, l_value, m, L, N)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown potential type: {potential_type}\")\n",
    "\n",
    "            # Save to cache\n",
    "            with open(cache_file, 'wb') as f:\n",
    "                pickle.dump(coefficients, f)\n",
    "            print(f\"Process {os.getpid()} saved coefficients to {cache_file}\")\n",
    "            \n",
    "            return coefficients\n",
    "\n",
    "    finally:\n",
    "        if got_lock and os.path.exists(lock_file):\n",
    "            os.remove(lock_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5363ca6f-ab42-4037-8ee6-961517db68f7",
   "metadata": {},
   "source": [
    "# Create Position Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75cf23ca-9b52-478e-8d33-9caac912fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quantum_evolution_animation(\n",
    "    l_value,\n",
    "    timestep_sampling=100,\n",
    "    polynomial_type=\"Lennard-Jones\",\n",
    "    polynomial_params=None,\n",
    "    centrifugal_params=None,\n",
    "    show_potential=True,\n",
    "):\n",
    "    # Construct file paths based on partial wave\n",
    "    System = f\"Ar-Ar_scattering_{L}L_{timestep}ts\"\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    subfolder = os.path.join(OUTPUT_DIR, f\"{QUBITS_NUM}q_PartialWaveSim_{System}_{current_date}\", f\"l_{l_value:04d}\")statevector_filename = os.path.join(subfolder, f\"statevectors_l{l_value}.txt\")\n",
    "    momentum_filename = os.path.join(subfolder, f\"momentum_l{l_value}.txt\")\n",
    "    \n",
    "    if not os.path.exists(statevector_filename) or not os.path.exists(momentum_filename):\n",
    "        print(f\"Data files not found for l={l_value}\")\n",
    "        return None\n",
    "    \n",
    "    # Load data with sampling\n",
    "    position_data = np.loadtxt(statevector_filename, delimiter='\\t')\n",
    "    momentum_data = np.loadtxt(momentum_filename, delimiter='\\t')\n",
    "    \n",
    "    # Sample every Nth timestep\n",
    "    position_data = position_data[::timestep_sampling]\n",
    "    momentum_data = momentum_data[::timestep_sampling]\n",
    "    \n",
    "    time = position_data[:, 0]\n",
    "    positions = position_data[:, 1:]\n",
    "    momentum_distributions = momentum_data[:, 1:]\n",
    "    \n",
    "    num_frames = len(time)\n",
    "    \n",
    "    # Position values\n",
    "    position_values = np.linspace(-d, d, N)\n",
    "    momentum_values = np.linspace(-Nyquist, Nyquist, N)\n",
    "    \n",
    "    # Calculate expectation values\n",
    "    expectation_values = [calculate_expectation_value(positions[i], position_values) for i in range(num_frames)]\n",
    "    momentum_expectation_values = [calculate_p_expectation_value(momentum_distributions[i], momentum_values) \n",
    "                                  for i in range(num_frames)]\n",
    "    \n",
    "    # Setup plots\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 15))\n",
    "    \n",
    "    # Position distribution subplot\n",
    "    ax1.set_xlabel('Position (a.u.)')\n",
    "    ax1.set_ylabel('Probability Amplitude')\n",
    "    bar_width = (position_values[1] - position_values[0]) * 0.8\n",
    "    bars = ax1.bar(position_values, positions[0], width=bar_width, color='blue', alpha=0.6)\n",
    "    ax1.set_xlim(-d, d)\n",
    "    ax1.set_title(f'l={l_value} Partial Wave, {polynomial_type} Potential')\n",
    "    \n",
    "    # Add potential overlay\n",
    "    if show_potential and polynomial_params is not None:\n",
    "        x_potential = position_values.copy()\n",
    "        x_potential[np.abs(x_potential) < 0.001] = 0.001\n",
    "        \n",
    "        # Calculate effective potential (LJ + centrifugal)\n",
    "        epsilon_eff = polynomial_params[0]\n",
    "        sigma_eff = polynomial_params[1]\n",
    "        \n",
    "        V_lj = 4 * epsilon_eff * ((sigma_eff/np.abs(x_potential))**12 - (sigma_eff/np.abs(x_potential))**6)\n",
    "        V_cent = 0 if l_value == 0 else (l_value * (l_value + 1)) / (2 * m * x_potential**2)\n",
    "        V_total = V_lj + V_cent\n",
    "        \n",
    "        ax1_pot = ax1.twinx()\n",
    "        ax1_pot.plot(x_potential, V_total, 'r-', linewidth=2, label='Total Potential')\n",
    "        ax1_pot.set_ylabel('Potential Energy (a.u.)', color='r')\n",
    "        ax1_pot.tick_params(axis='y', labelcolor='r')\n",
    "        ax1_pot.set_ylim(np.min(V_total[np.isfinite(V_total)]), \n",
    "                         min(np.max(V_total[np.isfinite(V_total)]), 0.01))\n",
    "    \n",
    "    time_box = ax1.text(0.02, 0.95, '', transform=ax1.transAxes, fontsize=14,\n",
    "                       verticalalignment='top', bbox=dict(facecolor='black', color='white'))\n",
    "    \n",
    "    # Position density evolution\n",
    "    ax2.set_xlabel('Time (a.u.)')\n",
    "    ax2.set_ylabel('Position (a.u.)')\n",
    "    ax2.set_title('Position Space Density Evolution')\n",
    "    \n",
    "    position_density = np.zeros((N, num_frames))\n",
    "    position_density_plot = ax2.imshow(position_density, aspect='auto',\n",
    "                                      extent=[time[0], time[-1], d, -d],\n",
    "                                      cmap='hot', interpolation='gaussian')\n",
    "    plt.colorbar(position_density_plot, ax=ax2, label='Probability Amplitude')\n",
    "    position_expectation_line, = ax2.plot([], [], 'c-', linewidth=2, label='<x>')\n",
    "    ax2.legend(loc='upper right')\n",
    "    \n",
    "    # Momentum distribution\n",
    "    ax3.set_xlabel('Momentum (a.u.)')\n",
    "    ax3.set_ylabel('Probability Amplitude')\n",
    "    ax3.set_title('Momentum Distribution')\n",
    "    momentum_line, = ax3.plot(momentum_values, momentum_distributions[0], 'g-', linewidth=2)\n",
    "    ax3.set_xlim(-Nyquist, Nyquist)\n",
    "    ax3.set_ylim(0, np.max(momentum_distributions) * 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    def update(frame):\n",
    "        for i, bar in enumerate(bars):\n",
    "            bar.set_height(positions[frame, i])\n",
    "        \n",
    "        time_box.set_text(f't = {time[frame]:.1f}')\n",
    "        \n",
    "        position_expectation_line.set_data(time[:frame + 1], expectation_values[:frame + 1])\n",
    "        \n",
    "        for t in range(frame + 1):\n",
    "            position_density[:, t] = positions[t, :]\n",
    "        position_density_plot.set_array(position_density)\n",
    "        \n",
    "        momentum_line.set_ydata(momentum_distributions[frame])\n",
    "        \n",
    "        return list(bars) + [time_box, position_expectation_line, position_density_plot, momentum_line]\n",
    "    \n",
    "    ani = animation.FuncAnimation(fig, update, frames=num_frames, blit=True, interval=50, repeat=False)\n",
    "    \n",
    "    # Save animation in same directory as data\n",
    "    animation_filename = os.path.join(subfolder, f\"evolution_l{l_value}_sampled{timestep_sampling}.gif\")\n",
    "    \n",
    "    try:\n",
    "        ani.save(animation_filename, writer='pillow', fps=20)\n",
    "        print(f\"Animation saved: {animation_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving animation for l={l_value}: {e}\")\n",
    "    \n",
    "    plt.close(fig)\n",
    "    return animation_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da13c1e2-ff30-4bac-91d2-3eaa635ba6db",
   "metadata": {},
   "source": [
    "# Create Momentum Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97670bb8-ce60-4422-b9f8-588e183db60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_momentum_evolution_animation(\n",
    "    l_value,\n",
    "    timestep_sampling=100,\n",
    "    polynomial_type=\"Lennard-Jones\",\n",
    "):\n",
    "    System = f\"Ar-Ar_scattering_{L}L_{timestep}ts\"\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    subfolder = os.path.join(OUTPUT_DIR, f\"{QUBITS_NUM}q_PartialWaveSim_{System}_{current_date}\", f\"l_{l_value:04d}\")\n",
    "    momentum_filename = os.path.join(subfolder, f\"momentum_l{l_value}.txt\")\n",
    "    \n",
    "    if not os.path.exists(momentum_filename):\n",
    "        print(f\"Momentum data file not found for l={l_value}\")\n",
    "        return None\n",
    "    \n",
    "    # Load data with sampling\n",
    "    momentum_data = np.loadtxt(momentum_filename, delimiter='\\t')\n",
    "    momentum_data = momentum_data[::timestep_sampling]\n",
    "    \n",
    "    time = momentum_data[:, 0]\n",
    "    momentum_distributions = momentum_data[:, 1:]\n",
    "    num_frames = len(time)\n",
    "    \n",
    "    # Momentum values\n",
    "    momentum_values = np.linspace(-Nyquist, Nyquist, N)\n",
    "    \n",
    "    # Calculate momentum expectation values\n",
    "    momentum_expectation_values = [calculate_p_expectation_value(momentum_distributions[i], momentum_values) \n",
    "                                  for i in range(num_frames)]\n",
    "    \n",
    "    # Calculate FFT for frequency analysis\n",
    "    fft_results = []\n",
    "    for i in range(num_frames):\n",
    "        fft_magnitude = np.abs(np.fft.fft(momentum_distributions[i]))\n",
    "        fft_results.append(fft_magnitude)\n",
    "    fft_results = np.array(fft_results)\n",
    "    \n",
    "    freq_values = np.fft.fftfreq(N, d=timestep * timestep_sampling)\n",
    "    positive_freq_mask = freq_values >= 0\n",
    "    freq_values_positive = freq_values[positive_freq_mask]\n",
    "    \n",
    "    # Setup plots\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 15))\n",
    "    \n",
    "    # Momentum density heatmap\n",
    "    ax1.set_xlabel('Time (a.u.)')\n",
    "    ax1.set_ylabel('Momentum (a.u.)')\n",
    "    ax1.set_title(f'l={l_value} Momentum Space Evolution')\n",
    "    \n",
    "    small = 1e-10\n",
    "    momentum_density_log = np.log10(momentum_distributions.T + small)\n",
    "    \n",
    "    momentum_density_plot = ax1.imshow(momentum_density_log, aspect='auto',\n",
    "                                      extent=[time[0], time[-1], Nyquist, -Nyquist],\n",
    "                                      cmap='viridis', interpolation='gaussian')\n",
    "    plt.colorbar(momentum_density_plot, ax=ax1, label='log₁₀(Probability)')\n",
    "    \n",
    "    momentum_expectation_line, = ax1.plot([], [], 'w-', linewidth=2, label='<p>')\n",
    "    ax1.legend(loc='upper right')\n",
    "    \n",
    "    # Current momentum distribution\n",
    "    ax2.set_xlabel('Momentum (a.u.)')\n",
    "    ax2.set_ylabel('Probability Amplitude')\n",
    "    ax2.set_title('Current Momentum Distribution')\n",
    "    momentum_line, = ax2.plot(momentum_values, momentum_distributions[0], 'b-', linewidth=2)\n",
    "    ax2.set_xlim(-Nyquist, Nyquist)\n",
    "    ax2.set_ylim(0, np.max(momentum_distributions) * 1.1)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    time_text = ax2.text(0.02, 0.95, '', transform=ax2.transAxes, fontsize=12,\n",
    "                        verticalalignment='top', bbox=dict(facecolor='white', edgecolor='black'))\n",
    "    \n",
    "    # Frequency spectrum\n",
    "    ax3.set_xlabel('Frequency (a.u.⁻¹)')\n",
    "    ax3.set_ylabel('Spectral Amplitude')\n",
    "    ax3.set_title('Frequency Spectrum')\n",
    "    \n",
    "    initial_fft_positive = fft_results[0][positive_freq_mask]\n",
    "    frequency_line, = ax3.plot(freq_values_positive, initial_fft_positive, 'g-', linewidth=2)\n",
    "    \n",
    "    max_freq_to_show = freq_values_positive[len(freq_values_positive)//4]\n",
    "    ax3.set_xlim(0, max_freq_to_show)\n",
    "    ax3.set_ylim(0, np.max(fft_results[:, positive_freq_mask]) * 1.1)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    def update(frame):\n",
    "        momentum_expectation_line.set_data(time[:frame + 1], momentum_expectation_values[:frame + 1])\n",
    "        momentum_line.set_ydata(momentum_distributions[frame])\n",
    "        time_text.set_text(f't = {time[frame]:.1f} a.u.')\n",
    "        \n",
    "        current_fft_positive = fft_results[frame][positive_freq_mask]\n",
    "        frequency_line.set_ydata(current_fft_positive)\n",
    "        \n",
    "        return [momentum_expectation_line, momentum_line, time_text, frequency_line]\n",
    "    \n",
    "    ani = animation.FuncAnimation(fig, update, frames=num_frames, blit=True, interval=50, repeat=False)\n",
    "    \n",
    "    # Save animation in same directory as data\n",
    "    animation_filename = os.path.join(subfolder, f\"momentum_l{l_value}_sampled{timestep_sampling}.gif\")\n",
    "    \n",
    "    try:\n",
    "        ani.save(animation_filename, writer='pillow', fps=20)\n",
    "        print(f\"Momentum animation saved: {animation_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving momentum animation for l={l_value}: {e}\")\n",
    "    \n",
    "    plt.close(fig)\n",
    "    return animation_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952bc06f-800c-40e0-ac72-24ada10b54dc",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4eb4e903-45fe-4d9f-83e3-11643eb13056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manage_resume_logic(sv_filename, mom_filename, start_time, stop_time, timestep, qubits_num, initial_state_params):\n",
    "    x_0, p_0, delta = initial_state_params\n",
    "    n_states = 2**qubits_num\n",
    "    \n",
    "    # Always start fresh - clear any existing files\n",
    "    print(f\"Process {os.getpid()}: Starting new simulation from t={start_time:.1f}\")\n",
    "    \n",
    "    # Clear existing files to ensure clean start\n",
    "    for filename in [sv_filename, mom_filename]:\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write('')  # Create empty file\n",
    "    \n",
    "    # Initialize fresh wavepacket\n",
    "    initial_psi = initialize_gaussian_wavepacket(x_0, p_0, delta)\n",
    "    current_statevector = np.zeros(n_states, dtype=complex)\n",
    "    current_statevector[:len(initial_psi)] = initial_psi\n",
    "    \n",
    "    return start_time, current_statevector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ca55deb-44e7-48de-805b-eba7656ad61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_timestep(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            return None\n",
    "        try:\n",
    "            with open(filename, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                if lines:\n",
    "                    last_line = lines[-1].strip()\n",
    "                    if last_line:\n",
    "                        return float(last_line.split('\\t')[0])\n",
    "        except:\n",
    "            return None\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ecd68a7-e342-4e7a-9203-e1062d73a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_partial_wave_standalone(l_value, lj_base_coeffs, centrifugal_base_coeffs, params):\n",
    "    FOLDER_NAME = params['folder_name']\n",
    "    QUBITS_NUM = params['qubits_num']\n",
    "    timestep = params['timestep']\n",
    "    start_time = params['start_time']\n",
    "    stop_time = params['stop_time']\n",
    "    current_params = params['current_params']\n",
    "    m = params['m']\n",
    "    x_0, p_0, delta = params['x_0'], params['p_0'], params['delta']\n",
    "    kinetic_coeffs = params['kinetic_coeffs']\n",
    "    vertical_offset = params['vertical_offset']\n",
    "\n",
    "    subfolder = os.path.join(FOLDER_NAME, f\"l_{l_value:04d}\")\n",
    "    os.makedirs(subfolder, exist_ok=True)\n",
    "    trotter_sv_filename = os.path.join(subfolder, f\"statevectors_l{l_value}.txt\")\n",
    "    trotter_mom_filename = os.path.join(subfolder, f\"momentum_l{l_value}.txt\")\n",
    "\n",
    "    try:\n",
    "        # Initialize batched recorder\n",
    "        recorder = BatchedDataRecorder(batch_size=100)\n",
    "        \n",
    "        # Always start fresh - no resume logic\n",
    "        resume_time, current_statevector = manage_resume_logic(\n",
    "            trotter_sv_filename, trotter_mom_filename, start_time, stop_time,\n",
    "            timestep, QUBITS_NUM, (x_0, p_0, delta)\n",
    "        )\n",
    "        \n",
    "        if resume_time >= stop_time:\n",
    "            print(f\"Process {os.getpid()}: l={l_value} already complete.\")\n",
    "            return l_value, True, \"Already completed\"\n",
    "\n",
    "        # Coefficient summing\n",
    "        centrifugal_params = [l_value, m]\n",
    "        coefficients_by_power = sum_cached_coefficients(\n",
    "            lj_base_coeffs, centrifugal_base_coeffs, current_params, centrifugal_params\n",
    "        )\n",
    "        \n",
    "        pot = EffectivePotential(\n",
    "            current_params, centrifugal_params, vertical_offset,\n",
    "            coefficients_by_power=coefficients_by_power\n",
    "        )\n",
    "        \n",
    "        # Construct circuit\n",
    "        position_register = QuantumRegister(QUBITS_NUM, name=\"position\")\n",
    "        simulator = Aer.get_backend('statevector_simulator')\n",
    "        current_time = resume_time\n",
    "\n",
    "        print(f\"Process {os.getpid()}: Starting l={l_value} from t={current_time:.1f}\")\n",
    "\n",
    "        # Main evolution loop\n",
    "        step_count = 0\n",
    "        \n",
    "        while current_time < stop_time:\n",
    "            circuit_mom = QuantumCircuit(position_register)\n",
    "            circuit_mom.initialize(current_statevector, list(position_register))\n",
    "            cqft(circuit_mom, position_register, QUBITS_NUM)\n",
    "            \n",
    "            record_momentum_distribution_batched(\n",
    "                circuit_mom, position_register, current_time, \n",
    "                recorder, trotter_mom_filename\n",
    "            )\n",
    "\n",
    "            circuit_evol = QuantumCircuit(position_register)\n",
    "            circuit_evol.initialize(current_statevector, list(position_register))\n",
    "            \n",
    "            # Kinetic evolution\n",
    "            cqft(circuit_evol, position_register, QUBITS_NUM)\n",
    "            kinetic_term(circuit_evol, position_register, QUBITS_NUM, timestep, kinetic_coeffs)\n",
    "            ciqft(circuit_evol, position_register, QUBITS_NUM)\n",
    "            \n",
    "            # Potential evolution\n",
    "            pot.apply_to_circuit(circuit_evol, position_register, timestep)\n",
    "\n",
    "            # Get evolved state\n",
    "            result = simulator.run(circuit_evol).result()\n",
    "            current_state = Statevector(result.get_statevector())\n",
    "            current_statevector = current_state.data\n",
    "\n",
    "            # Record Positions\n",
    "            rho = DensityMatrix(current_state).data\n",
    "            state_vector_probs = np.real(np.diag(rho))\n",
    "            recorder.add_position_record(\n",
    "                current_time + timestep, state_vector_probs, \n",
    "                trotter_sv_filename\n",
    "            )\n",
    "\n",
    "            current_time += timestep\n",
    "            step_count += 1\n",
    "            \n",
    "            # Periodically clean up finished threads\n",
    "            if step_count % 1000 == 0:\n",
    "                recorder.cleanup_finished_threads()\n",
    "                print(f\"Process {os.getpid()}: l={l_value}, t={current_time:.1f}/{stop_time}\")\n",
    "\n",
    "        # Final flush, wait for writes\n",
    "        print(f\"Process {os.getpid()}: Flushing data for l={l_value}...\")\n",
    "        recorder.flush_all()\n",
    "        \n",
    "        print(f\"Process {os.getpid()}: Completed l={l_value}\")\n",
    "        return l_value, True, None\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error for l={l_value}: {e}\"\n",
    "        print(f\"Process {os.getpid()}: {error_msg}\")\n",
    "        with open(os.path.join(subfolder, \"error.txt\"), 'w') as f:\n",
    "            f.write(f\"{datetime.now()}\\n{error_msg}\\n{traceback.format_exc()}\")\n",
    "        return l_value, False, str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91c202ff-0345-4e04-9e50-4a7231f177d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_parallel_partial_waves_main(n_cores, lj_base_coeffs, centrifugal_base_coeffs):\n",
    "\n",
    "    l_values = list(range(0, 31))\n",
    "\n",
    "    System = f\"Ar-Ar_scattering_{QUBITS_NUM}q_{timestep}ts\"\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    FOLDER_NAME = os.path.join(OUTPUT_DIR,\n",
    "                               f\"{QUBITS_NUM}q_PartialWaveSim_{System}_{current_date}\")\n",
    "    os.makedirs(FOLDER_NAME, exist_ok=True)\n",
    "\n",
    "    print(f\"Output folder: {FOLDER_NAME}\")\n",
    "\n",
    "    shared_params = {\n",
    "        'folder_name': FOLDER_NAME,\n",
    "        'cache_dir': CACHE_DIR,\n",
    "        'qubits_num': QUBITS_NUM,\n",
    "        'N': N, 'L': L, 'd': d,\n",
    "        'timestep': timestep,\n",
    "        'start_time': start_time, 'stop_time': stop_time,\n",
    "        'current_params': current_params,\n",
    "        'polynomial_type': PolynomialType,\n",
    "        'm': m,\n",
    "        'mass': m, 'x_0': x_0, 'p_0': p_0, 'delta': δ,\n",
    "        'kinetic_coeffs': kinetic_coeffs,\n",
    "        'vertical_offset': vertical_offset\n",
    "    }\n",
    "\n",
    "    params_file = os.path.join(FOLDER_NAME, \"simulation_parameters.json\")\n",
    "    with open(params_file, 'w') as f:\n",
    "        # Convert numpy arrays to lists for JSON serialization\n",
    "        params_to_save = shared_params.copy()\n",
    "        for key, value in params_to_save.items():\n",
    "            if isinstance(value, np.ndarray):\n",
    "                params_to_save[key] = value.tolist()\n",
    "        json.dump(params_to_save, f, indent=4)\n",
    "    print(f\"Simulation parameters saved to {params_file}\")\n",
    "\n",
    "    print(f\"\\nStarting parallel simulations for {len(l_values)} partial waves...\")\n",
    "    print(f\"Using {n_cores} parallel cores for l = {min(l_values)} to {max(l_values)}.\")\n",
    "\n",
    "    worker_args = [\n",
    "        (l, lj_base_coeffs, centrifugal_base_coeffs, shared_params) for l in l_values\n",
    "    ]\n",
    "    \n",
    "    start_time_total = datetime.now()\n",
    "    results = []\n",
    "    with mp.Pool(processes=n_cores) as pool:\n",
    "        with tqdm(total=len(l_values), desc=\"Partial waves completed\") as pbar:\n",
    "            for result in pool.starmap(run_single_partial_wave_standalone, worker_args):\n",
    "                results.append(result)\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Process results\n",
    "    successful_runs = [r[0] for r in results if r[1]]\n",
    "    failed_runs = [(r[0], r[2]) for r in results if not r[1]]\n",
    "    end_time_total = datetime.now()\n",
    "\n",
    "    print_summary(FOLDER_NAME, len(l_values), n_cores, successful_runs, failed_runs, start_time_total, end_time_total)\n",
    "\n",
    "def print_summary(folder, total, n_cores, successful, failed, start_time, end_time):\n",
    "    duration = end_time - start_time\n",
    "    summary = (\n",
    "        f\"\\n{'='*60}\\n\"\n",
    "        f\"All simulations completed\\n\"\n",
    "        f\"Total time: {duration}\\n\"\n",
    "        f\"Successful runs: {len(successful)}/{total}\\n\"\n",
    "        f\"Failed runs: {len(failed)}/{total}\\n\"\n",
    "        f\"Results saved in: {folder}\\n\"\n",
    "        f\"{'='*60}\\n\"\n",
    "    )\n",
    "    print(summary)\n",
    "\n",
    "    summary_file = os.path.join(folder, \"simulation_summary.txt\")\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(f\"Completion time: {datetime.now()}\\n\" + summary)\n",
    "        if failed:\n",
    "            f.write(\"\\nFailed l values and errors:\\n\")\n",
    "            for l_val, err in failed:\n",
    "                f.write(f\"  l={l_val}: {err}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db42e3a-b8ec-4f4f-96ee-9ef50cf81a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System has 32 cores available. Using 32 for this simulation.\n",
      "\n",
      "============================================================\n",
      "Pre-calculating or loading base coefficients...\n",
      "✓ Base coefficients ready in 0.00 seconds.\n",
      "============================================================\n",
      "\n",
      "Output folder: /scratch/jmc03846/simulation_output/11q_PartialWaveSim_Ar-Ar_scattering_11q_30.0ts_2025-09-01\n",
      "Simulation parameters saved to /scratch/jmc03846/simulation_output/11q_PartialWaveSim_Ar-Ar_scattering_11q_30.0ts_2025-09-01/simulation_parameters.json\n",
      "\n",
      "Starting parallel simulations for 31 partial waves...\n",
      "Using 32 parallel cores for l = 0 to 30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Partial waves completed:   0%|          | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 2291424: Starting new simulation from t=0.0Process 2291425: Starting new simulation from t=0.0Process 2291426: Starting new simulation from t=0.0\n",
      "\n",
      "Process 2291427: Starting new simulation from t=0.0\n",
      "\n",
      "Process 2291428: Starting new simulation from t=0.0\n",
      "Process 2291424: Starting l=0 from t=0.0Process 2291430: Starting new simulation from t=0.0\n",
      "Process 2291426: Starting l=2 from t=0.0Process 2291429: Starting new simulation from t=0.0\n",
      "Process 2291425: Starting l=1 from t=0.0Process 2291431: Starting new simulation from t=0.0Process 2291432: Starting new simulation from t=0.0Process 2291427: Starting l=3 from t=0.0Process 2291435: Starting new simulation from t=0.0Process 2291436: Starting new simulation from t=0.0Process 2291428: Starting l=4 from t=0.0Process 2291433: Starting new simulation from t=0.0Process 2291439: Starting new simulation from t=0.0Process 2291437: Starting new simulation from t=0.0Process 2291438: Starting new simulation from t=0.0Process 2291440: Starting new simulation from t=0.0Process 2291441: Starting new simulation from t=0.0Process 2291442: Starting new simulation from t=0.0Process 2291443: Starting new simulation from t=0.0\n",
      "Process 2291434: Starting new simulation from t=0.0Process 2291444: Starting new simulation from t=0.0\n",
      "Process 2291445: Starting new simulation from t=0.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Process 2291446: Starting new simulation from t=0.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Process 2291447: Starting new simulation from t=0.0\n",
      "Process 2291448: Starting new simulation from t=0.0\n",
      "\n",
      "Process 2291449: Starting new simulation from t=0.0\n",
      "Process 2291450: Starting new simulation from t=0.0Process 2291430: Starting l=6 from t=0.0Process 2291435: Starting l=11 from t=0.0Process 2291438: Starting l=14 from t=0.0Process 2291429: Starting l=5 from t=0.0Process 2291434: Starting l=10 from t=0.0Process 2291440: Starting l=16 from t=0.0Process 2291446: Starting l=22 from t=0.0Process 2291432: Starting l=8 from t=0.0Process 2291439: Starting l=15 from t=0.0\n",
      "\n",
      "Process 2291431: Starting l=7 from t=0.0Process 2291443: Starting l=19 from t=0.0\n",
      "Process 2291433: Starting l=9 from t=0.0\n",
      "Process 2291445: Starting l=21 from t=0.0\n",
      "\n",
      "\n",
      "\n",
      "Process 2291451: Starting new simulation from t=0.0\n",
      "Process 2291442: Starting l=18 from t=0.0\n",
      "\n",
      "Process 2291436: Starting l=12 from t=0.0\n",
      "Process 2291441: Starting l=17 from t=0.0\n",
      "\n",
      "Process 2291444: Starting l=20 from t=0.0\n",
      "\n",
      "\n",
      "\n",
      "Process 2291447: Starting l=23 from t=0.0Process 2291437: Starting l=13 from t=0.0Process 2291448: Starting l=24 from t=0.0\n",
      "\n",
      "\n",
      "\n",
      "Process 2291449: Starting l=25 from t=0.0\n",
      "Process 2291452: Starting new simulation from t=0.0\n",
      "Process 2291450: Starting l=26 from t=0.0Process 2291451: Starting l=27 from t=0.0\n",
      "Process 2291453: Starting new simulation from t=0.0\n",
      "Process 2291452: Starting l=28 from t=0.0\n",
      "\n",
      "Process 2291454: Starting new simulation from t=0.0\n",
      "Process 2291453: Starting l=29 from t=0.0\n",
      "Process 2291454: Starting l=30 from t=0.0\n",
      "Process 2291424: l=0, t=30000.0/3000010.0\n",
      "Process 2291447: l=23, t=30000.0/3000010.0Process 2291436: l=12, t=30000.0/3000010.0\n",
      "\n",
      "Process 2291427: l=3, t=30000.0/3000010.0\n",
      "Process 2291446: l=22, t=30000.0/3000010.0\n",
      "Process 2291443: l=19, t=30000.0/3000010.0\n",
      "Process 2291440: l=16, t=30000.0/3000010.0\n",
      "Process 2291445: l=21, t=30000.0/3000010.0\n",
      "Process 2291448: l=24, t=30000.0/3000010.0\n",
      "Process 2291454: l=30, t=30000.0/3000010.0\n",
      "Process 2291449: l=25, t=30000.0/3000010.0\n",
      "Process 2291434: l=10, t=30000.0/3000010.0\n",
      "Process 2291441: l=17, t=30000.0/3000010.0\n",
      "Process 2291425: l=1, t=30000.0/3000010.0\n",
      "Process 2291442: l=18, t=30000.0/3000010.0\n",
      "Process 2291452: l=28, t=30000.0/3000010.0\n",
      "Process 2291431: l=7, t=30000.0/3000010.0\n",
      "Process 2291444: l=20, t=30000.0/3000010.0\n",
      "Process 2291439: l=15, t=30000.0/3000010.0\n",
      "Process 2291453: l=29, t=30000.0/3000010.0\n",
      "Process 2291426: l=2, t=30000.0/3000010.0\n",
      "Process 2291430: l=6, t=30000.0/3000010.0\n",
      "Process 2291433: l=9, t=30000.0/3000010.0\n",
      "Process 2291437: l=13, t=30000.0/3000010.0\n",
      "Process 2291438: l=14, t=30000.0/3000010.0\n",
      "Process 2291428: l=4, t=30000.0/3000010.0\n",
      "Process 2291432: l=8, t=30000.0/3000010.0\n",
      "Process 2291451: l=27, t=30000.0/3000010.0\n",
      "Process 2291429: l=5, t=30000.0/3000010.0\n",
      "Process 2291435: l=11, t=30000.0/3000010.0\n",
      "Process 2291450: l=26, t=30000.0/3000010.0\n",
      "Process 2291424: l=0, t=60000.0/3000010.0\n",
      "Process 2291436: l=12, t=60000.0/3000010.0\n",
      "Process 2291447: l=23, t=60000.0/3000010.0\n",
      "Process 2291443: l=19, t=60000.0/3000010.0\n",
      "Process 2291449: l=25, t=60000.0/3000010.0\n",
      "Process 2291454: l=30, t=60000.0/3000010.0\n",
      "Process 2291445: l=21, t=60000.0/3000010.0\n",
      "Process 2291448: l=24, t=60000.0/3000010.0\n",
      "Process 2291440: l=16, t=60000.0/3000010.0\n",
      "Process 2291434: l=10, t=60000.0/3000010.0\n",
      "Process 2291427: l=3, t=60000.0/3000010.0\n",
      "Process 2291452: l=28, t=60000.0/3000010.0\n",
      "Process 2291441: l=17, t=60000.0/3000010.0\n",
      "Process 2291431: l=7, t=60000.0/3000010.0\n",
      "Process 2291439: l=15, t=60000.0/3000010.0\n",
      "Process 2291442: l=18, t=60000.0/3000010.0\n",
      "Process 2291428: l=4, t=60000.0/3000010.0\n",
      "Process 2291446: l=22, t=60000.0/3000010.0\n",
      "Process 2291453: l=29, t=60000.0/3000010.0\n",
      "Process 2291444: l=20, t=60000.0/3000010.0\n",
      "Process 2291433: l=9, t=60000.0/3000010.0\n",
      "Process 2291430: l=6, t=60000.0/3000010.0\n",
      "Process 2291432: l=8, t=60000.0/3000010.0\n",
      "Process 2291425: l=1, t=60000.0/3000010.0\n",
      "Process 2291429: l=5, t=60000.0/3000010.0\n",
      "Process 2291435: l=11, t=60000.0/3000010.0\n",
      "Process 2291426: l=2, t=60000.0/3000010.0\n",
      "Process 2291438: l=14, t=60000.0/3000010.0\n",
      "Process 2291451: l=27, t=60000.0/3000010.0\n",
      "Process 2291437: l=13, t=60000.0/3000010.0\n",
      "Process 2291450: l=26, t=60000.0/3000010.0\n",
      "Process 2291424: l=0, t=90000.0/3000010.0\n",
      "Process 2291436: l=12, t=90000.0/3000010.0\n",
      "Process 2291443: l=19, t=90000.0/3000010.0\n",
      "Process 2291449: l=25, t=90000.0/3000010.0\n",
      "Process 2291454: l=30, t=90000.0/3000010.0\n",
      "Process 2291447: l=23, t=90000.0/3000010.0\n",
      "Process 2291448: l=24, t=90000.0/3000010.0\n",
      "Process 2291440: l=16, t=90000.0/3000010.0\n",
      "Process 2291445: l=21, t=90000.0/3000010.0\n",
      "Process 2291424: l=0, t=120000.0/3000010.0\n",
      "Process 2291434: l=10, t=90000.0/3000010.0\n",
      "Process 2291452: l=28, t=90000.0/3000010.0\n",
      "Process 2291439: l=15, t=90000.0/3000010.0\n",
      "Process 2291441: l=17, t=90000.0/3000010.0\n",
      "Process 2291428: l=4, t=90000.0/3000010.0\n",
      "Process 2291431: l=7, t=90000.0/3000010.0\n",
      "Process 2291442: l=18, t=90000.0/3000010.0\n",
      "Process 2291444: l=20, t=90000.0/3000010.0\n",
      "Process 2291453: l=29, t=90000.0/3000010.0\n",
      "Process 2291427: l=3, t=90000.0/3000010.0\n",
      "Process 2291432: l=8, t=90000.0/3000010.0\n",
      "Process 2291433: l=9, t=90000.0/3000010.0\n",
      "Process 2291429: l=5, t=90000.0/3000010.0\n",
      "Process 2291430: l=6, t=90000.0/3000010.0\n",
      "Process 2291435: l=11, t=90000.0/3000010.0\n",
      "Process 2291446: l=22, t=90000.0/3000010.0\n",
      "Process 2291451: l=27, t=90000.0/3000010.0\n",
      "Process 2291425: l=1, t=90000.0/3000010.0\n",
      "Process 2291426: l=2, t=90000.0/3000010.0\n",
      "Process 2291438: l=14, t=90000.0/3000010.0\n",
      "Process 2291437: l=13, t=90000.0/3000010.0\n",
      "Process 2291450: l=26, t=90000.0/3000010.0\n",
      "Process 2291424: l=0, t=150000.0/3000010.0\n",
      "Process 2291443: l=19, t=120000.0/3000010.0\n",
      "Process 2291436: l=12, t=120000.0/3000010.0\n",
      "Process 2291449: l=25, t=120000.0/3000010.0\n",
      "Process 2291447: l=23, t=120000.0/3000010.0\n",
      "Process 2291440: l=16, t=120000.0/3000010.0\n",
      "Process 2291454: l=30, t=120000.0/3000010.0\n",
      "Process 2291445: l=21, t=120000.0/3000010.0\n",
      "Process 2291439: l=15, t=120000.0/3000010.0\n",
      "Process 2291452: l=28, t=120000.0/3000010.0\n",
      "Process 2291434: l=10, t=120000.0/3000010.0\n",
      "Process 2291441: l=17, t=120000.0/3000010.0\n",
      "Process 2291448: l=24, t=120000.0/3000010.0Process 2291428: l=4, t=120000.0/3000010.0\n",
      "\n",
      "Process 2291431: l=7, t=120000.0/3000010.0\n",
      "Process 2291444: l=20, t=120000.0/3000010.0\n",
      "Process 2291442: l=18, t=120000.0/3000010.0\n",
      "Process 2291453: l=29, t=120000.0/3000010.0\n",
      "Process 2291429: l=5, t=120000.0/3000010.0\n",
      "Process 2291432: l=8, t=120000.0/3000010.0\n",
      "Process 2291446: l=22, t=120000.0/3000010.0\n",
      "Process 2291435: l=11, t=120000.0/3000010.0\n",
      "Process 2291451: l=27, t=120000.0/3000010.0\n",
      "Process 2291433: l=9, t=120000.0/3000010.0\n",
      "Process 2291426: l=2, t=120000.0/3000010.0\n",
      "Process 2291427: l=3, t=120000.0/3000010.0\n",
      "Process 2291425: l=1, t=120000.0/3000010.0\n",
      "Process 2291430: l=6, t=120000.0/3000010.0\n",
      "Process 2291438: l=14, t=120000.0/3000010.0\n",
      "Process 2291450: l=26, t=120000.0/3000010.0\n",
      "Process 2291437: l=13, t=120000.0/3000010.0\n",
      "Process 2291424: l=0, t=180000.0/3000010.0\n",
      "Process 2291443: l=19, t=150000.0/3000010.0\n",
      "Process 2291436: l=12, t=150000.0/3000010.0\n",
      "Process 2291449: l=25, t=150000.0/3000010.0\n",
      "Process 2291447: l=23, t=150000.0/3000010.0\n",
      "Process 2291440: l=16, t=150000.0/3000010.0\n",
      "Process 2291439: l=15, t=150000.0/3000010.0\n",
      "Process 2291434: l=10, t=150000.0/3000010.0\n",
      "Process 2291452: l=28, t=150000.0/3000010.0\n",
      "Process 2291428: l=4, t=150000.0/3000010.0\n",
      "Process 2291441: l=17, t=150000.0/3000010.0\n",
      "Process 2291454: l=30, t=150000.0/3000010.0\n",
      "Process 2291444: l=20, t=150000.0/3000010.0\n",
      "Process 2291448: l=24, t=150000.0/3000010.0\n",
      "Process 2291431: l=7, t=150000.0/3000010.0\n",
      "Process 2291442: l=18, t=150000.0/3000010.0\n",
      "Process 2291445: l=21, t=150000.0/3000010.0\n",
      "Process 2291453: l=29, t=150000.0/3000010.0\n",
      "Process 2291446: l=22, t=150000.0/3000010.0\n",
      "Process 2291429: l=5, t=150000.0/3000010.0\n",
      "Process 2291425: l=1, t=150000.0/3000010.0\n",
      "Process 2291450: l=26, t=150000.0/3000010.0\n",
      "Process 2291426: l=2, t=150000.0/3000010.0\n",
      "Process 2291432: l=8, t=150000.0/3000010.0\n",
      "Process 2291451: l=27, t=150000.0/3000010.0\n",
      "Process 2291435: l=11, t=150000.0/3000010.0\n",
      "Process 2291427: l=3, t=150000.0/3000010.0\n",
      "Process 2291433: l=9, t=150000.0/3000010.0\n",
      "Process 2291430: l=6, t=150000.0/3000010.0\n",
      "Process 2291437: l=13, t=150000.0/3000010.0\n",
      "Process 2291438: l=14, t=150000.0/3000010.0\n",
      "Process 2291424: l=0, t=210000.0/3000010.0\n"
     ]
    }
   ],
   "source": [
    "def main(n_cores=None):\n",
    "    epsilon = 0.00011\n",
    "    sigma = 5.2\n",
    "    epsilon_scaled = 4*epsilon\n",
    "\n",
    "    if n_cores is None:\n",
    "        n_cores = min(32, mp.cpu_count())\n",
    "    print(f\"System has {mp.cpu_count()} cores available. Using {n_cores} for this simulation.\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Pre-calculating or loading base coefficients...\")\n",
    "    start_coeff_time = time.time()\n",
    "\n",
    "    lj_base_coeffs = compute_and_cache_coefficients(\n",
    "        \"Lennard-Jones\", [epsilon_scaled, sigma], QUBITS_NUM,\n",
    "        max_power=12, cache_dir=CACHE_DIR\n",
    "    )\n",
    "\n",
    "    centrifugal_base_coeffs = compute_and_cache_coefficients(\n",
    "        \"Centrifugal\", [1.0, 1.0], QUBITS_NUM,\n",
    "        max_power=2, cache_dir=CACHE_DIR\n",
    "    )\n",
    "\n",
    "    end_coeff_time = time.time()\n",
    "    print(f\"Base coefficients ready in {end_coeff_time - start_coeff_time:.2f} seconds.\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    run_parallel_partial_waves_main(n_cores, lj_base_coeffs, centrifugal_base_coeffs)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Simulations complete. Generating animations for successful runs...\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    l_values_to_animate = list(range(0,1))\n",
    "\n",
    "    # Timestep sampling rate. A higher number means fewer frames,\n",
    "    #    a smaller file size, and faster generation.\n",
    "    animation_sampling_rate = 200\n",
    "\n",
    "    # The animation functions need to find the output folder.\n",
    "    System = f\"Ar-Ar_scattering_{L}L_{timestep}ts\"\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    FOLDER_NAME = os.path.join(OUTPUT_DIR,\n",
    "                               f\"{QUBITS_NUM}q_PartialWaveSim_{System}_{current_date}\")\n",
    "\n",
    "    # Check if the main output folder exists to avoid errors\n",
    "    if not os.path.exists(FOLDER_NAME):\n",
    "        print(f\"Error: Output folder not found at {FOLDER_NAME}\")\n",
    "        print(\"Cannot generate animations. Please ensure simulations ran correctly.\")\n",
    "        return\n",
    "\n",
    "    # Loop through each l-value and attempt to create its animations\n",
    "    for l_val in l_values_to_animate:\n",
    "        # Check if the data for this specific l-value exists, as some may have failed\n",
    "        subfolder = os.path.join(FOLDER_NAME, f\"l_{l_val:04d}\")\n",
    "        if os.path.exists(subfolder) and os.path.exists(os.path.join(subfolder, f\"statevectors_l{l_val}.txt\")):\n",
    "            print(f\"\\n Generating animations for l={l_val}\")\n",
    "            try:\n",
    "                # Call the function to create the position-space evolution animation\n",
    "                create_quantum_evolution_animation(\n",
    "                    l_value=l_val,\n",
    "                    timestep_sampling=animation_sampling_rate,\n",
    "                    polynomial_type=PolynomialType,\n",
    "                    polynomial_params=current_params,\n",
    "                    centrifugal_params=[l_val, m],\n",
    "                    show_potential=True\n",
    "                )\n",
    "\n",
    "                # Call the function to create the momentum-space evolution animation\n",
    "                create_momentum_evolution_animation(\n",
    "                    l_value=l_val,\n",
    "                    timestep_sampling=animation_sampling_rate,\n",
    "                    polynomial_type=PolynomialType\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Could not generate animation for l={l_val}. Error: {e}\")\n",
    "        else:\n",
    "            print(f\"Skipping animations for l={l_val} (data not found).\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"All animations generated.\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46803241-8852-454d-8a29-a4d874dc96cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
